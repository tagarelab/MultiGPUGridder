<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>Multi-GPU Gridding: Multi-GPU Gridding Index Page</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Multi-GPU Gridding
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Multi-GPU Gridding Index Page </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="Introduction"></a>
Introduction</h1>
<p>For many applications, it is needed to perform many iterations of forward and back projection in the Fourier domain. Here, we provide a class for fast forward and back projection which utilizes multiple NVIDIA GPUs, CUDA, and C++ along with a wrapper for calling all the functions from within Matlab or from within Python.</p>
<h1><a class="anchor" id="Dependencies"></a>
Dependencies</h1>
<table class="doxtable">
<tr>
<th>Library </th><th>Version </th><th>Usage  </th></tr>
<tr>
<td><b>CUDA</b> </td><td>&gt;= 10.0 </td><td>Used for calling the GPU functions and processing data on the GPU. </td></tr>
<tr>
<td><b>NVCC</b> </td><td>&gt;= 10.0 </td><td>NVIDIA CUDA compiler for compiling the GPU code. This should be included with the CUDA download. </td></tr>
<tr>
<td><b>C++ Compiler</b> </td><td>&gt;= C++11 </td><td>A C++ compiler is needed for compiling the C++ code. </td></tr>
<tr>
<td><b>Nvidia GPU</b> </td><td>&gt;=3.0 Compute capability </td><td>Between 1 and 12 NVIDIA GPUs are required. </td></tr>
<tr>
<td><b>Matlab</b> </td><td>&gt;= R2018a </td><td>Optional: If compiling the MATLAB wrappers for calling the class. </td></tr>
<tr>
<td><b>Python</b> </td><td>&gt;= 3.0 </td><td>Optional: If compiling the Python wrappers for calling the class. </td></tr>
</table>
<h1><a class="anchor" id="install_sec"></a>
Installation</h1>
<h3>Step 1: Clone or download the GitHub repository to your computer.</h3>
<h3>Step 2: Open the CMake GUI with the source code path to be the "src" folder and the binaries path to be a new folder name "bin".</h3>
<h3>Step 3: Within CMake, click on Configure</h3>
<h3>Step 4: Check or uncheck the optional settings (such as BUILD_TESTS and WITH_MATLAB).</h3>
<h3>Step 5: Click configure again and then click on Generate.</h3>
<h3>Step 6 (Windows): Click on Open Project which should open Visual Studio. Then right click on ALL_BUILD and click on build. Decide between Debug or Release (see the drop down on the top center within Visual Studio).</h3>
<h3>Step 6 (Linux): Close CMake and open a terminal within the bin folder (which was created by CMake). Within the terminal type "make" which will then compile the code.</h3>
<h3>Step 7: Optionally, run the units tests within Matlab and / or Python to check everything is functioning correctly.</h3>
<h1><a class="anchor" id="Video"></a>
Tutorial</h1>
<p><a href="https://youtu.be/gO2kiizHO4g">Please see the video tutorial for further details and examples of the software</a></p>
<h1><a class="anchor" id="Example"></a>
Example</h1>
<p>Here is a simple example on running the Matlab wrapper: </p><pre class="fragment">% Add the required Matlab file paths
mfilepath=fileparts(which('MultiGPUGridder_Matlab_Class.m'));
addpath(genpath(fullfile(mfilepath)));

% Parameters for creating the volume and coordinate axes
VolumeSize = 128;
interpFactor = 2;
n1_axes = 100;
n2_axes = 100;

% Create the volume
load mri;
MRI_volume = squeeze(D);
MRI_volume = imresize3(MRI_volume,[VolumeSize, VolumeSize, VolumeSize]);

% Define the projection directions
coordAxes = create_uniform_axes(n1_axes,n2_axes,0,10);

% Create the gridder object
gridder = MultiGPUGridder_Matlab_Class(VolumeSize, n1_axes * n2_axes, interpFactor);

% Set the volume
gridder.setVolume(MRI_volume);

% Run the forward projection
images = gridder.forwardProject(coordAxes);    
easyMontage(images, 1)

% Run the back projection
gridder.resetVolume();
gridder.backProject(gridder.Images, coordAxes)

vol=gridder.getVol();
easyMontage(vol, 2)

% Reconstruct the volume
reconstructVol = gridder.reconstructVol();
easyMontage(reconstructVol, 3)
</pre><div class="image">
<img src="../../Documentation/Images/Matlab_Example.png"  alt="Matlab_Example"/>
</div>
<h1><a class="anchor" id="matlab_unit_tests"></a>
Matlab - Unit Tests</h1>
<p>The package also provides units tests to run within Matlab. The tests verify that each CUDA kernel returns the expected output. Additionally, there are unit tests for the forward and back projection kernels which test the output from each GPU, a combintation of GPUs, and varied parameters such as the volume size, number of projection directions, and the number of CUDA streams. In order to run the unit tests, go to the /src/unit_tests folder. Then within Matlab, run the Run_Unit_Tests.m script.</p>
<p>For changing the testing parameters (such as if your computer has a different number of GPUs), modify the GPU_Device parameter at the top of FilterTest.m, ForwardProjectTests.m, and BackProjectTests.m. Also feel free to modify the other testing parameters as well.</p>
<h1><a class="anchor" id="cuda"></a>
CUDA - Asynchronous memory transfers</h1>
<p>For large datasets, there is significant copying of data to/from the GPUs. CUDA allows for overlapping of memory transfers and kernel executation (see <a href="https://devblogs.nvidia.com/how-overlap-data-transfers-cuda-cc/">NVIDIA documentation for further information</a>. This greatly lowers the computation time for large datasets. CUDA streams allow us to perform this.</p>
<div class="image">
<img src="../../Documentation/Images/CUDA_Streaming_Overview.png"  alt="CUDA_Streaming_Overview"/>
</div>
<p>For example, in the <a class="el" href="classgpu_gridder.html#ae11f5283443a948896f1c48b6dd7c577">gpuGridder::ForwardProject</a> function, we perform asynchronous (async) memory transfers from the host (i.e.the CPU) to the device (i.e.the GPU). The following simplified code illustrates this </p><pre class="fragment">cudaMemcpyAsync(
    d_CoordAxes-&gt;GetPointer(),
    h_CoordAxes-&gt;GetPointer(),
    bytes,
    cudaMemcpyHostToDevice,
    CUDA_Stream);
</pre><p>A <b>bytes</b> length of memory from the host memory pointer <b>h_CoordAxes-&gt;GetPointer()</b> to the device memory pointer <b>d_CoordAxes-&gt;GetPointer()</b> is copied using the <b>CUDA_Stream</b>. A corresponding call can be used to copy device memory back to the host.</p>
<h1><a class="anchor" id="cuda"></a>
CUDA - Asynchronous memory transfers</h1>
<p>Similarly to the memory transfers, we also use CUDA streams for calling the GPU kernels. This lets us create a queue of work for each GPU to execute simultaneously. The included filters also use CUDA streams such as the <a class="el" href="class_f_f_t_shift2_d_filter.html" title="A filter for 2D FFT shift on a GPU array. ">FFTShift2DFilter</a> as shown below </p><pre class="fragment">// Run a FFTShift on each 2D slice
FFTShift2DFilter&lt;cufftComplex&gt; *FFTShiftFilter = new FFTShift2DFilter&lt;cufftComplex&gt;();
FFTShiftFilter-&gt;SetInput(Images);
FFTShiftFilter-&gt;SetImageSize(ImageSize);
FFTShiftFilter-&gt;SetNumberOfSlices(nSlices);
FFTShiftFilter-&gt;Update(&amp;stream);
</pre><p>The CUDA stream is assigned by simply passing the reference to the stream (&amp;stream) to the <a class="el" href="class_f_f_t_shift2_d_filter.html#a734a7e3aab1d3812b0470682973fe423" title="Update the filter. ">FFTShift2DFilter::Update</a> function. The other filters work in the same way.</p>
<h1><a class="anchor" id="matlab_wrapper"></a>
Matlab Wrapper - Memory Persistance</h1>
<p>First, we need to have the host memory persistant when going back to Matlab in order to only need to allocate both the host and device memory once.</p>
<p>We achieved this though the <a class="el" href="mex_function_wrapper_8h.html">mexFunctionWrapper.h</a>. This header file and associated functions are used for keeping both the host (i.e. CPU) and the device (i.e. GPU) memory persisant when going back and forth to Matlab. Essentially, when the <a class="el" href="class_multi_g_p_u_gridder.html" title="A class for gridding on multiple GPUs. ">MultiGPUGridder</a> object is created, the corresponding memory pointer is converted to a <b>real uint64 scalar</b> and returned to Matlab. This scalar is remembered within the Matlab class (by the <b>objectHandle</b> member). Then, after the object is created, when a mex function is called the objectHandle (i.e.the <b>real uint64 scalar</b>) is passed from Matlab to the C++ code and then recasted back into the <a class="el" href="class_multi_g_p_u_gridder.html" title="A class for gridding on multiple GPUs. ">MultiGPUGridder</a> C++ object. This allows us to maintain the memory between Matlab mex function calls.</p>
<p>Therefore, each of the mex functions has this line of code: </p><pre class="fragment">MultiGPUGridder *MultiGPUGridderObj = convertMat2Ptr&lt;MultiGPUGridder&gt;(prhs[0]);
</pre><p>The prhs[0] refers to the first variable sent from Matlab (see the Matlab documentation on the prhs). The prhs stands for right hand side (i.e.the inputs) while the plhs stands for the left hand side (i.e.the outputs), similarly to Matlab functions.</p>
<p>The </p><pre class="fragment">convertMat2Ptr&lt;&gt;()
</pre><p>function takes the <b>real uint64 scalar</b> (which was passed from the Matlab class to the mex function) and casts the pointer to the <a class="el" href="class_multi_g_p_u_gridder.html" title="A class for gridding on multiple GPUs. ">MultiGPUGridder</a> class to get the object back. The <a class="el" href="mex_function_wrapper_8h.html#a2d2408d782ddafe6a991334da37ff1d5">convertPtr2Mat&lt;&gt;()</a> function does that opposite (convert the memory pointer to a real uint64 scalar) to return back to Matlab.</p>
<h1><a class="anchor" id="matlab_in_place"></a>
Matlab Wrapper - In-place computation</h1>
<p>In order to avoid unnecessary copying to and from Matlab as well as to avoid unneeded memory allocation, we perform the calculations in place. The steps were then</p>
<ol type="1">
<li>Matlab allocated the arrays (within Matlab) the standard way. For example, X = zeros(64, 64, 64).</li>
<li>Using the mexSetVariables wrapper, the mex function mxGetData() was used to get the memory pointer to the Matlab allocated array.</li>
<li>The pointer was then passed to the <a class="el" href="class_multi_g_p_u_gridder.html" title="A class for gridding on multiple GPUs. ">MultiGPUGridder</a> object.</li>
<li>The memory was directly read using the pointer any output was copied to the corresponding memory location.</li>
<li>After returning to Matlab, the associated changes to the array are displayed within Matlab (without the need to copy to/from Matlab).</li>
</ol>
<p>For a specific example, when setting the array which corresponds to the volumethe mexSetVariables was called with the following inputs: (1) a string 'SetVolume' to specify which array we're passing, (2) objectHandle (i.e.the real uint64 scalar which corresponds to the <a class="el" href="class_multi_g_p_u_gridder.html" title="A class for gridding on multiple GPUs. ">MultiGPUGridder</a> object created in mexCreateGridder), (3) the volume, and (4) a vector with the volume dimenstions. Within mexSetVariables, the function call was the following: </p><pre class="fragment">// Pointer to the volume array and the dimensions of the array
MultiGPUGridderObj-&gt;SetVolume((float *)mxGetData(prhs[2]), (int *)mxGetData(prhs[3]));
</pre><p>Then within the <a class="el" href="class_abstract_gridder.html" title="A class for the gridder interface. ">AbstractGridder</a> (which is the parent class of the <a class="el" href="class_multi_g_p_u_gridder.html" title="A class for gridding on multiple GPUs. ">MultiGPUGridder</a> class) the SetVolume function is the following </p><pre class="fragment">void AbstractGridder::SetVolume(float *Volume, int *ArraySize)
{
    // First save the given pointer
    if (this-&gt;VolumeInitialized == false)
    {
        this-&gt;h_Volume = new HostMemory&lt;float&gt;(3, ArraySize);
        this-&gt;h_Volume-&gt;CopyPointer(Volume);
        this-&gt;h_Volume-&gt;PinArray();

        this-&gt;VolumeInitialized = true;
    }
    else
    {
        // Just copy the pointer
        this-&gt;h_Volume-&gt;CopyPointer(Volume);
    }
}
</pre><p>Here, we create a new <a class="el" href="class_host_memory.html" title="A class for allocating host (i.e. CPU) memory. ">HostMemory</a> object and copy the pointer of the Matlab allocated array. We lastly pin the memory to allow for asynchronous memory transfer to and from the GPUs. Please see the <a href="https://devblogs.nvidia.com/how-overlap-data-transfers-cuda-cc/">NVIDIA documentation for further information</a>.</p>
<h1><a class="anchor" id="matlab_mex"></a>
Matlab Wrapper - Mex Functions</h1>
<table class="doxtable">
<tr>
<th>Mex Wrapper File Name </th><th>Purpose  </th></tr>
<tr>
<td>mexCreateGridder </td><td>Creates the <a class="el" href="class_multi_g_p_u_gridder.html" title="A class for gridding on multiple GPUs. ">MultiGPUGridder</a> object </td></tr>
<tr>
<td>mexDeleteGridder </td><td>Deletes and deallocates the <a class="el" href="class_multi_g_p_u_gridder.html" title="A class for gridding on multiple GPUs. ">MultiGPUGridder</a> object </td></tr>
<tr>
<td>mexSetVariables </td><td>Passes the pointers from the Matlab allocated arrays to the <a class="el" href="class_multi_g_p_u_gridder.html" title="A class for gridding on multiple GPUs. ">MultiGPUGridder</a> object </td></tr>
<tr>
<td>mexMultiGPUForwardProject </td><td>Calls the forward projection function </td></tr>
<tr>
<td>mexMultiGPUBackProject </td><td>Call the back projection function </td></tr>
<tr>
<td>mexMultiGPUGetVolume </td><td>Runs an inverse FFT to get the volume </td></tr>
<tr>
<td>mexMultiGPUReconstructVolume </td><td>Normalizes by the plane density and runs an inverse FFT to get the volume </td></tr>
</table>
<p>The mexCreateGridder creates an instance of the <a class="el" href="class_multi_g_p_u_gridder.html" title="A class for gridding on multiple GPUs. ">MultiGPUGridder</a> class. The <a class="el" href="class_multi_g_p_u_gridder.html" title="A class for gridding on multiple GPUs. ">MultiGPUGridder</a> class then creates an instance of the <a class="el" href="classgpu_gridder.html" title="A class for gridding on the GPU. ">gpuGridder</a> class with one <a class="el" href="classgpu_gridder.html" title="A class for gridding on the GPU. ">gpuGridder</a> object per GPU. Then in the mexMultiGPUForwardProject function for example, the <a class="el" href="class_multi_g_p_u_gridder.html" title="A class for gridding on multiple GPUs. ">MultiGPUGridder</a> object simply iterates over the <a class="el" href="classgpu_gridder.html" title="A class for gridding on the GPU. ">gpuGridder</a> objects and calls the <a class="el" href="classgpu_gridder.html#ae11f5283443a948896f1c48b6dd7c577">gpuGridder::ForwardProject</a> function. See the figure below for a graphical representation of this.</p>
<div class="image">
<img src="../../Documentation/Images/Multi_GPU_Gridder_Overview.png"  alt="Multi_GPU_Gridder_Overview"/>
</div>
 </div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Wed Dec 2 2020 10:18:08 for Multi-GPU Gridding by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
</body>
</html>
